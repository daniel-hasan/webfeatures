{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "def get_unigram_tagger(dataset_corpus):\n",
    "  p_train = 0.9\n",
    "  tagged_sents = dataset_corpus.tagged_sents()\n",
    "  size = int(len(tagged_sents)*0.9)\n",
    "  train_sents = tagged_sents[:size]\n",
    "  test_sents = tagged_sents[size:]\n",
    "  uni_tagger = nltk.UnigramTagger(train_sents)\n",
    "  print(f\"Test accuracy unigram = {uni_tagger.evaluate(test_sents)}\")\n",
    "  return uni_tagger\n",
    "\n",
    "def get_bigram_tagger(dataset_corpus):\n",
    "  p_train = 0.9\n",
    "  tagged_sents = dataset_corpus.tagged_sents()\n",
    "  size = int(len(tagged_sents)*0.9)\n",
    "  train_sents = tagged_sents[:size]\n",
    "  test_sents = tagged_sents[size:]\n",
    "  bi_tagger = nltk.BigramTagger(train_sents)\n",
    "  print(f\"Test accuracy bigram = {bi_tagger.evaluate(test_sents)}\")\n",
    "  return bi_tagger\n",
    "\n",
    "def get_trigram_tagger(dataset_corpus):\n",
    "  p_train = 0.9\n",
    "  tagged_sents = dataset_corpus.tagged_sents()\n",
    "  size = int(len(tagged_sents)*0.9)\n",
    "  train_sents = tagged_sents[:size]\n",
    "  test_sents = tagged_sents[size:]\n",
    "  tri_tagger = nltk.TrigramTagger(train_sents)\n",
    "  print(f\"Test accuracy trigram = {tri_tagger.evaluate(test_sents)}\")\n",
    "  return tri_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy unigram = 0.806511963200714\n",
      "Test accuracy bigram = 0.20826610826954103\n",
      "Test accuracy trigram = 0.1179585321478837\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import mac_morpho\n",
    "uni_tagger = get_unigram_tagger(mac_morpho)\n",
    "bi_tagger = get_bigram_tagger(mac_morpho)\n",
    "tri_tagger = get_trigram_tagger(mac_morpho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../postag_models/pt_macmorpho_unigram.pickle\",\"wb\") as file_tagger:\n",
    "    pickle.dump(uni_tagger_pt,file_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Olá', 'IN'), ('!', '!'), ('Meu', 'PROADJ'), ('nome', 'N'), ('é', 'V'), ('Daniel', 'NPROP')]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../postag_models/pt_unigram.pickle\",\"rb\") as file_tagger:\n",
    "    tagger = pickle.load(file_tagger)\n",
    "    print(tagger.tag([\"Olá\",\"!\",\"Meu\",\"nome\", \"é\",\"Daniel\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unigram: [('lula', 'comida'), ('é', 'V'), ('a', None), ('comida', 'S'), ('que', None), ('o', 'A'), ('presidente', 'S'), ('lula', 'comida'), ('gosta', 'V')]\n",
      "\n",
      "Bigram: [('lula', 'comida'), ('é', 'V'), ('a', 'ART'), ('comida', 'S'), ('que', None), ('o', 'A'), ('presidente', 'S'), ('lula', 'comida'), ('gosta', 'V')]\n",
      "\n",
      "trigram: [('lula', 'comida'), ('é', 'V'), ('a', 'ART'), ('comida', 'S'), ('que', None), ('o', 'A'), ('presidente', 'S'), ('lula', 'comida'), ('gosta', 'V')]\n"
     ]
    }
   ],
   "source": [
    "#http://www.inf.ed.ac.uk/teaching/courses/icl/nltk/tagging.pdf\n",
    "\n",
    "tagged_sents = mac_morpho.tagged_sents()[:10]\n",
    "\n",
    "train_sents = [[(\"eu\",\"P\"),(\"gosto\",\"V\"),(\"da\",\"PREP\"),(\"comida\", \"S\"),(\"lula\",\"comida\"),],\n",
    "                [(\"o\",\"A\"),(\"presidente\",\"S\"),(\"lula\",\"pessoa\"),(\"é\",\"V\"),(\"do\", \"PREP\"), (\"PT\", \"partido\")],\n",
    "                [(\"ele\",\"P\"),(\"gosta\",\"V\"),(\"de\",\"PREP\"),(\"lula\",\"comida\"),]\n",
    "               ]\n",
    "\n",
    "test_sents = [\"lula\",\"é\",\"a\",\"comida\",\"que\", \"o\",\"presidente\",\"lula\", \"gosta\"]\n",
    "\n",
    "                                     \n",
    "#unigran tager: a tag mais comum\n",
    "uni_tagger = nltk.UnigramTagger(train_sents)\n",
    "uni_result = uni_tagger.tag(test_sents)\n",
    "print(f\"\\nUnigram: {uni_result}\")\n",
    "\n",
    "bi_tagger = nltk.BigramTagger(tagged_sents, backoff=uni_tagger)\n",
    "bi_result = bi_tagger.tag(test_sents)\n",
    "print(f\"\\nBigram: {bi_result}\")\n",
    "\n",
    "tri_tagger = nltk.TrigramTagger(tagged_sents, backoff=bi_tagger)\n",
    "tri_result = tri_tagger.tag(test_sents)\n",
    "print(f\"\\ntrigram: {tri_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/manu/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy =0.8849353534083527\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "uni_tagger_en = get_unigram_tagger(brown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../postag_models/en_brown_unigram.pickle\",\"wb\") as file_tagger:\n",
    "    pickle.dump(uni_tagger_en,file_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PPS'), ('was', 'BEDZ'), ('good', 'JJ'), ('to', 'TO'), ('know', 'VB'), ('himself', 'PPL'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../postag_models/en_unigram.pickle\",\"rb\") as file_tagger:\n",
    "    tagger = pickle.load(file_tagger)\n",
    "    print(tagger.tag([\"It\",\"was\",\"good\",\"to\",\"know\", \"himself\", \"!\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_cat to /home/manu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/cess_cat.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('cess_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy =0.8861314447816858\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cess_cat\n",
    "uni_tagger_es = get_unigram_tagger(cess_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../postag_models/es_cess_esp_unigram.pickle\",\"wb\") as file_tagger:\n",
    "    pickle.dump(uni_tagger_es,file_tagger)\n",
    "with open(\"../postag_models/es_unigram.pickle\",\"wb\") as file_tagger:\n",
    "    pickle.dump(uni_tagger_es,file_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hola', None), ('!', 'Fat'), ('joy', None), ('me', 'pp1cs000'), ('lhamo', None), ('es', 'p0000000'), ('manu', None)]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../postag_models/es_unigram.pickle\",\"rb\") as file_tagger:\n",
    "    tagger = pickle.load(file_tagger)\n",
    "    print(tagger.tag([\"Hola\",\"!\",\"joy\", \"me\",\"lhamo\", \"es\",\"manu\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package alpino to /home/manu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/alpino.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('alpino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy =0.806867875833393\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "from nltk.corpus import alpino\n",
    "uni_tagger_du = get_unigram_tagger(alpino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../postag_models/du_alpino_unigram.pickle\",\"wb\") as file_tagger:\n",
    "    pickle.dump(uni_tagger_du,file_tagger)\n",
    "with open(\"../postag_models/du_unigram.pickle\",\"wb\") as file_tagger:\n",
    "    pickle.dump(uni_tagger_du,file_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hallo', 'noun'), ('!', 'punct'), ('mijn', 'det'), ('naam', 'noun'), ('is', 'verb'), ('Mia', 'noun')]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../postag_models/du_unigram.pickle\",\"rb\") as file_tagger:\n",
    "    tagger = pickle.load(file_tagger)\n",
    "    print(tagger.tag([\"hallo\",\"!\",\"mijn\",\"naam\", \"is\",\"Mia\"]))"
=======
    "#http://www.inf.ed.ac.uk/teaching/courses/icl/nltk/tagging.pdf\n",
    "\n",
    "tagged_sents = mac_morpho.tagged_sents()[:10]\n",
    "\n",
    "train_sents = [[(\"eu\",\"P\"),(\"gosto\",\"V\"),(\"de\",\"PREP\"),(\"lula\",\"comida\"),],\n",
    "                [(\"o\",\"A\"),(\"presidente\",\"S\"),(\"lula\",\"pessoa\"),(\"lul\",\"S\")],\n",
    "                [(\"boa\",\"gretting\"),(\"tarde\",\"gretting\"),(\"ela\",\"P\"),(\"gosto\",\"V\"),(\"de\",\"PREP\"),(\"lula\",\"comida\"),]\n",
    "               ]\n",
    "\n",
    "test_sents = [\"lula\",\"é\",\"a\",\"comida\",\"preferida\",\"do\",\"presidente\",\"lula\",\"lul\"]\n",
    "\n",
    "\n",
    "\n",
    "#unigran tager: a tag mais comum\n",
    "uni_tagger = nltk.UnigramTagger(train_sents)\n",
    "uni_result = uni_tagger.tag(test_sents)\n",
    "print(f\"\\nUnigram: {uni_result}\")\n",
    "\n",
    "bi_tagger = nltk.BigramTagger(train_sents)\n",
    "bi_result = bi_tagger.tag(test_sents)\n",
    "print(f\"\\nBigram: {bi_result}\")\n",
    "\n",
    "tri_tagger = nltk.TrigramTagger(train_sents)\n",
    "tri_result = tri_tagger.tag(test_sents)\n",
    "print(f\"\\ntrigram: {tri_result}\")"
>>>>>>> ec8ed5e240822cfd3efa66df9b37fd7ecf63bf7c
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
